{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc4149c",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91f2cf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: tensor([[-0.8148, -0.6732,  0.6201, -0.7203],\n",
      "        [ 0.4579, -1.3416,  0.3622,  0.8046],\n",
      "        [-0.9765, -0.2673,  0.5145, -0.9443]])\n",
      "K: tensor([[ 0.5445, -0.2472, -0.5106,  0.3801],\n",
      "        [ 0.3474,  0.7532,  0.3604,  0.3090],\n",
      "        [ 0.5478, -0.6361, -0.4861,  0.1562]])\n",
      "V: tensor([[ 0.0738, -0.3870,  0.5922, -0.0558],\n",
      "        [-0.3937,  0.2503,  1.0458, -0.3767],\n",
      "        [ 0.4121, -0.5704,  0.4220,  0.1439]])\n",
      "is representation: tensor([ 0.1260, -0.3377,  0.6101, -0.0341])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import math\n",
    "\n",
    "X_i = torch.tensor([[ 0.12, -0.87,  0.33,  0.45],\n",
    "                    [ 0.76,  0.21, -0.34,  0.67],\n",
    "                  # [-0.55,  0.18,  0.29, -0.73], \n",
    "# We remove the token \"a\" since the sentence is only \"this is translation\".\n",
    "                    [ 0.03, -0.99,  0.42,  0.11]])\n",
    "\n",
    "W_Q = torch.tensor([[ 0.12, -0.87,  0.33,  0.45],\n",
    "                    [ 0.76,  0.21, -0.34,  0.67],\n",
    "                    [-0.55,  0.18,  0.29, -0.73],\n",
    "                    [ 0.03, -0.99,  0.42,  0.11]])\n",
    "\n",
    "W_K = torch.tensor([[ 0.64, -0.27,  0.89, -0.12],\n",
    "                    [-0.45,  0.33,  0.71,  0.08],\n",
    "                    [ 0.19, -0.94,  0.56,  0.37],\n",
    "                    [ 0.03,  0.85, -0.41,  0.76]])\n",
    "\n",
    "W_V = torch.tensor([[ 0.58, -0.13,  0.94,  0.22 ],\n",
    "                    [-0.31,  0.66, -0.74,  0.09],\n",
    "                    [ 0.45,  0.11, -0.88,  0.67],\n",
    "                    [-0.92,  0.37,  0.28, -0.50]])\n",
    "\n",
    "# Calculate Q, K, and V...\n",
    "Q = torch.matmul(X_i, W_Q)\n",
    "K = torch.matmul(X_i, W_K)\n",
    "V = torch.matmul(X_i, W_V)\n",
    "\n",
    "print(\"Q:\", Q)\n",
    "print(\"K:\", K)\n",
    "print(\"V:\", V)\n",
    "\n",
    "# Define the scaled dot product attention function...\n",
    "def scaled_dot_product_attention(Q: Tensor, K: Tensor, V: Tensor, d: int):\n",
    "    scaling_factor = 1 / math.sqrt(d)\n",
    "\n",
    "    attn_weight = torch.matmul(Q, K.T) * scaling_factor\n",
    "    attn_weight = torch.softmax(attn_weight, dim=1)\n",
    "    return torch.matmul(attn_weight, V)\n",
    "\n",
    "reps = scaled_dot_product_attention(Q, K, V, 4)\n",
    "is_repr = reps[1]\n",
    "print(\"is representation:\", is_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c69cd1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "W_Q_1, W_Q_2 = torch.chunk(W_Q, 2, dim=1)\n",
    "W_K_1, W_K_2 = torch.chunk(W_K, 2, dim=1)\n",
    "W_V_1, W_V_2 = torch.chunk(W_V, 2, dim=1)\n",
    "\n",
    "head_1 = scaled_dot_product_attention(X_i @ W_Q_1, X_i @ W_K_1, X_i @ W_V_1, 2)\n",
    "head_2 = scaled_dot_product_attention(X_i @ W_Q_2, X_i @ W_K_2, X_i @ W_V_2, 2)\n",
    "\n",
    "print(head_1.size())\n",
    "print(head_2.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
